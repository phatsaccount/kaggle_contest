\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Phát Hiện Hành Vi Chuột Đa Tác Tử Sử Dụng XGBoost và Kỹ Thuật Tạo Đặc Trưng Nâng Cao}

\author{
\IEEEauthorblockN{Lê Bảo Lân}
\IEEEauthorblockA{\textit{Công Nghệ Thông Tin} \\
\textit{Trường Đại học Công Nghệ}\\
Hà Nội, Việt Nam \\
23020098@vnu.edu.vn}
\and
\IEEEauthorblockN{Nguyễn Ngọc Phát}
\IEEEauthorblockA{\textit{Công Nghệ Thông Tin} \\
\textit{Trường Đại học Công Nghệ}\\
Hà Nội, Việt Nam \\
23020131@vnu.edu.vn}
\and
\IEEEauthorblockN{Nguyễn Duy Lâm}
\IEEEauthorblockA{\textit{Công Nghệ Thông Tin} \\
\textit{Trường Đại học Công Nghệ}\\
Hà Nội, Việt Nam \\
23020095@vnu.edu.vn}
}

\maketitle

\begin{abstract}
Bài báo này đề xuất một phương pháp học máy cho việc nhận dạng tự động hành vi xã hội của chuột từ dữ liệu tọa độ theo dõi video. Chúng tôi phát triển một framework dựa trên XGBoost với hơn 150 đặc trưng thời gian, không gian và tương tác xã hội. Phương pháp giải quyết các thách thức chính: (i) gán nhãn thưa (90\% nhãn thiếu), (ii) tỷ lệ pixel không đồng nhất, và (iii) phát hiện ranh giới hành vi theo thời gian. Hệ thống sử dụng chiến lược huấn luyện phân cấp với bộ phân loại nhị phân cho từng phần và từng hành động, kết hợp kiểm định chéo 3 lần và tối ưu hóa ngưỡng qua Optuna. Hậu xử lý bao gồm làm mịn Gaussian và làm sạch thời gian. Kết quả thực nghiệm chứng minh hiệu quả của phương pháp trên chỉ số Mouse F-beta, với thời gian chạy 10-12 giờ và bộ nhớ 12-14GB. Mã nguồn có sẵn tại: \url{https://github.com/phatsaccount/kaggle_contest}
\end{abstract}

\begin{IEEEkeywords}
nhận dạng hành vi, XGBoost, kỹ thuật tạo đặc trưng, phân tích thời gian, tương tác xã hội, phân tích hành vi động vật
\end{IEEEkeywords}

\section{Giới Thiệu}

Phân tích tự động hành vi động vật là một bài toán quan trọng trong nghiên cứu thần kinh học, phát triển thuốc và các nghiên cứu hành vi \cite{anderson2014toward}. Phương pháp gán nhãn thủ công truyền thống từ video ghi hình không chỉ tốn thời gian mà còn mang tính chủ quan và dễ không nhất quán. Thử Thách MABe (Multi-Agent Behavior) được phát triển để giải quyết vấn đề này thông qua việc cung cấp một tập dữ liệu quy mô lớn các tọa độ theo dõi chuột và yêu cầu phân loại tự động các hành vi xã hội.

Bài toán đặt ra là: cho trước các tọa độ theo dõi của các bộ phận cơ thể cho nhiều con chuột theo thời gian, hãy dự đoán các đoạn thời gian mà các hành vi cụ thể xảy ra. Tập dữ liệu đưa ra nhiều thách thức: (i) 90\% video huấn luyện thiếu chú thích hành vi, (ii) tỷ lệ pixel-sang-centimet thay đổi giữa các video, (iii) hành vi có ranh giới thời gian rõ ràng, (iv) hành vi cặp đôi yêu cầu mô hình hóa động lực giữa các tác tử, và (v) sự hiện diện của dữ liệu bị hỏng/không đầy đủ.

Các đóng góp chính của chúng tôi bao gồm: (1) Framework kỹ thuật tạo đặc trưng trích xuất hơn 150 đặc trưng thời gian và không gian, (2) Chiến lược huấn luyện phân cấp xử lý cấu hình bộ phận cơ thể theo từng phần, (3) Các đặc trưng động lực xã hội mới cho mô hình hóa tương tác cặp đôi, (4) Pipeline kiểm tra chất lượng dữ liệu và chuẩn hóa mạnh mẽ, và (5) Triển khai hiệu quả trong các ràng buộc tính toán.

\section{Công Trình Liên Quan}

\textbf{Nhận dạng hành vi động vật.} Các tiến bộ gần đây trong thị giác máy tính đã cho phép phân tích hành vi tự động \cite{mathis2018deeplabcut, pereira2019sleap}. Các phương pháp truyền thống dựa vào đặc trưng thủ công \cite{kabra2013jaaba}, trong khi học sâu học biểu diễn từ dữ liệu thô \cite{luxem2022identifying}.

\textbf{Gradient boosting.} XGBoost \cite{chen2016xgboost} hiệu quả cho dữ liệu có cấu trúc và chuỗi thời gian nhờ khả năng xử lý tương tác đặc trưng phức tạp và giá trị thiếu, với điều chuẩn ngăn chặn quá khớp.

\textbf{Phân tích hành vi xã hội.} Mô hình hóa tương tác xã hội yêu cầu các đặc trưng cá nhân và quan hệ. Nghiên cứu trước chỉ ra tầm quan trọng của đặc trưng khoảng cách, hướng và vận tốc \cite{segalin2021mouse}.

\section{Phương Pháp Luận}

\subsection{Tổng Quan Hệ Thống}

Hệ thống đề xuất bao gồm năm thành phần: (i) Tải dữ liệu và tiền xử lý, (ii) Kỹ thuật tạo đặc trưng, (iii) Huấn luyện mô hình, (iv) Hậu xử lý, và (v) Tạo bài nộp. Hình~\ref{fig:architecture} minh họa pipeline đầy đủ.

% --- PHẦN CHÈN ẢNH PIPELINE ---
\begin{figure}[htbp]
    \centering
    % LƯU Ý: Hãy đổi tên file ảnh của bạn thành pipeline.jpg và để cùng thư mục
    \includegraphics[width=0.95\linewidth]{ML_img.png}
    \caption{Sơ đồ luồng xử lý (Pipeline) của hệ thống đề xuất.}
    \label{fig:architecture}
\end{figure}
% ------------------------------

\subsection{Tiền Xử Lý Dữ Liệu}

\subsubsection{Kiểm Tra Chất Lượng}
Chúng tôi triển khai kiểm tra chất lượng dữ liệu để xác định các video bị hỏng:
\begin{itemize}
    \item Loại bỏ các video có ít hơn 100 khung hình
    \item Lọc các video có >50\% tọa độ NaN
    \item Xử lý ngoại lệ FileNotFoundError một cách uyển chuyển
\end{itemize}

\subsubsection{Chuẩn Hóa Tọa Độ}
Tọa độ pixel thô được chuẩn hóa sang đơn vị vật lý (centimet) sử dụng metadata \texttt{pix\_per\_cm\_approx}:
\begin{equation}
    \mathbf{c}_{\text{norm}} = \frac{\mathbf{c}_{\text{pixel}}}{\text{pix\_per\_cm\_approx}}
\end{equation}
Việc chuẩn hóa này là cần thiết vì mỗi video có độ phân giải khác nhau, dẫn đến tỷ lệ pixel-sang-centimet thay đổi. Chuẩn hóa đảm bảo rằng cùng một khoảng di chuyển vật lý (ví dụ 5cm) được biểu diễn nhất quán giữa các video, cho phép mô hình học các mẫu hành vi bất biến với độ phân giải camera.

\subsubsection{Thích Ứng Tốc Độ Khung Hình}
Tất cả các tham số cửa sổ thời gian được tỷ lệ theo tốc độ khung hình của mỗi video:
\begin{equation}
    w_{\text{scaled}} = \max\left(1, \left\lfloor w_{\text{base}} \cdot \frac{\text{fps}}{30.0} + 0.5 \right\rfloor\right)
\end{equation}
trong đó $w_{\text{base}}$ là kích thước cửa sổ tham chiếu tại 30 FPS. Cơ chế này đảm bảo tính nhất quán về thời gian vật lý; ví dụ, cửa sổ 30 khung hình ở 30 FPS (1 giây) sẽ tự động mở rộng thành 60 khung hình ở 60 FPS để bao phủ cùng khoảng thời gian thực. Ràng buộc $\max(1, \cdot)$ đảm bảo cửa sổ tối thiểu, trong khi làm tròn $\lfloor \cdot + 0.5 \rfloor$ giữ kích thước nguyên.

\subsection{Kỹ Thuật Tạo Đặc Trưng}

Chiến lược trích xuất đặc trưng của chúng tôi bao gồm tám danh mục với tổng cộng hơn 150 đặc trưng.

\subsubsection{Các Đặc Trưng Hình Học Cơ Bản}
Với mỗi khung hình, chúng tôi tính toán khoảng cách bình phương giữa tất cả các bộ phận cơ thể được theo dõi:
\begin{equation}
    d_{ij} = (x_i - x_j)^2 + (y_i - y_j)^2
\end{equation}

Độ dãn dài cơ thể và các đặc trưng góc nắm bắt tư thế:
\begin{equation}
    \text{elongation} = \frac{d_{\text{nose,tail}}}{d_{\text{ear\_left,ear\_right}} + \epsilon}
\end{equation}

\begin{equation}
    \text{body\_angle} = \frac{\mathbf{v}_{\text{nose}} \cdot \mathbf{v}_{\text{tail}}}{|\mathbf{v}_{\text{nose}}| \cdot |\mathbf{v}_{\text{tail}}| + \epsilon}
\end{equation}

\subsubsection{Các Đặc Trưng Vận Tốc Đa Tỷ Lệ}
Vận tốc được tính là dịch chuyển trung tâm cơ thể trên mỗi đơn vị thời gian:
\begin{equation}
    v(t) = \sqrt{(\Delta x)^2 + (\Delta y)^2} \cdot \text{fps}
\end{equation}
trong đó $\Delta x = x(t) - x(t-1)$ và $\Delta y = y(t) - y(t-1)$ là dịch chuyển liên tiếp. Nhân với tốc độ khung hình chuyển đổi từ cm/khung sang cm/giây, đảm bảo tính tương đương về vận tốc vật lý giữa các video có FPS khác nhau.

Chúng tôi trích xuất thống kê ở nhiều tỷ lệ thời gian $w \in \{20, 40, 60, 80\}$ khung hình:
\begin{align}
    \mu_{v,w}(t) &= \frac{1}{w} \sum_{i=t-w/2}^{t+w/2} v(i) \\
    \sigma_{v,w}(t) &= \sqrt{\frac{1}{w} \sum_{i=t-w/2}^{t+w/2} (v(i) - \mu_{v,w})^2}
\end{align}
Phương sai $\sigma_{v,w}$ đặc biệt quan trọng trong việc phân biệt hành vi: giá trị cao chỉ ra chuyển động không đều (tấn công, trốn tránh), trong khi giá trị thấp đặc trưng cho hoạt động ổn định (chải lông, ngửi).

\subsubsection{Độ Cong và Tốc Độ Quay}
Độ cong đường đi được tính bằng vận tốc và gia tốc:
\begin{equation}
    \kappa(t) = \frac{|v_x a_y - v_y a_x|}{(v_x^2 + v_y^2)^{3/2} + \epsilon}
\end{equation}
Tử số biểu diễn tích có hướng giữa vector vận tốc và gia tốc, đo lường tốc độ thay đổi hướng, trong khi mẫu số chuẩn hóa theo độ lớn vận tốc với $\epsilon = 10^{-6}$ để ổn định số học.

Tốc độ quay đo vận tốc góc:
\begin{equation}
    \omega(t) = \sum_{i=t-w/2}^{t+w/2} |\Delta \theta(i)|
\end{equation}
trong đó $\Delta \theta(i) = \theta(i) - \theta(i-1)$ là thay đổi hướng liên tiếp với $\theta = \arctan2(v_y, v_x)$.

\subsubsection{Các Đặc Trưng Trạng Thái Chuyển Động}
Vận tốc được rời rạc hóa thành các trạng thái dựa trên ngưỡng:
\begin{equation}
    s(t) = \begin{cases}
        0 & \text{nếu } v(t) < 0.5 \cdot \text{fps} \text{  (ngủ/nghi)} \\
        1 & \text{nếu } 0.5 \cdot \text{fps} \leq v(t) < 2.0 \cdot \text{fps} \text{  (chậm)} \\
        2 & \text{nếu } 2.0 \cdot \text{fps} \leq v(t) < 5.0 \cdot \text{fps} \text{  (trung bình)} \\
        3 & \text{nếu } v(t) \geq 5.0 \cdot \text{fps} \text{  (nhanh)}
    \end{cases}
\end{equation}
Các ngưỡng tỷ lệ với FPS đảm bảo phân loại nhất quán: ở 30 FPS, chúng tương ứng 15, 60, 150 cm/s, phân biệt hành vi tĩnh (chải lông), khám phá chậm, và rượt đuổi nhanh.

\subsubsection{Các Đặc Trưng Ngữ Cảnh Thời gian}
Chúng tôi nắm bắt các mẫu hoạt động gần đây so với dài hạn:
\begin{align}
    v_{\text{recent}}(t) &= \text{mean}_{i \in [t-30, t]} v(i) \\
    v_{\text{long}}(t) &= \text{mean}_{i \in [t-90, t]} v(i) \\
    \rho_v(t) &= \frac{v_{\text{recent}}(t)}{v_{\text{long}}(t) + \epsilon}
\end{align}
Tỷ số $\rho_v$ cung cấp ngữ cảnh hành vi: $\rho_v > 1$ chỉ ra tăng tốc, $\rho_v < 1$ phản ánh chậm lại.

Các đợt hoạt động (activity bursts) được phát hiện khi:
\begin{equation}
    \text{burst}(t) = \mathbb{1}[v_{\text{recent}}(t) > 2 \cdot v_{\text{long}}(t)]
\end{equation}
đánh dấu chuyển động đột ngột đặc trưng cho tấn công, rượt đuổi, hoặc trốn tránh.

\subsubsection{Các Đặc Trưng Động Lực Xã Hội (Chế Độ Cặp Đôi)}
Với các tương tác cặp đôi, chúng tôi tính toán động lực tiến/lùi:
\begin{equation}
    \text{approach\_speed}(t) = -\frac{d}{dt} d_{AB}(t) = -(d_{AB}(t) - d_{AB}(t-1)) \cdot \text{fps}
\end{equation}
trong đó $d_{AB}$ là khoảng cách liên-tác-tử. Dấu âm làm cho giá trị dương khi khoảng cách giảm (tiến gần) và âm khi tăng (rút lui).

Tương hỗ đối diện được xác định bởi sự thẳng hàng hướng:
\begin{align}
    \cos\theta_A &= \frac{\mathbf{v}_A \cdot \mathbf{r}_{AB}}{|\mathbf{v}_A| \cdot |\mathbf{r}_{AB}|} \\
    \cos\theta_B &= \frac{\mathbf{v}_B \cdot \mathbf{r}_{BA}}{|\mathbf{v}_B| \cdot |\mathbf{r}_{BA}|}
\end{align}
trong đó $\mathbf{v}_A$ và $\mathbf{r}_{AB}$ là vector vận tốc và vị trí tương đối.

\begin{equation}
    \text{mutual\_facing} = \mathbb{1}[\cos\theta_A > 0.7 \land \cos\theta_B > 0.7]
\end{equation}
Ngưỡng 0.7 ($\approx 45^\circ$) xác định khi cả hai chuột hướng vào nhau.

Dấu hiệu đuổi kết hợp tiến gần với vận tốc tương đối:
\begin{equation}
    \text{chase\_score} = \text{mean}_{w} [\mathbb{1}[\Delta d < 0] \cdot \mathbb{1}[v_B > 0.8 v_A]]
\end{equation}
điều kiện kép đòi hỏi khoảng cách giảm ($\Delta d < 0$) và vận tốc mục tiêu cao hơn người đuổi ($v_B > 0.8 v_A$).

\subsubsection{Các Đặc Trưng Thời Gian Tầm Dài}
Trung bình động có trọng số mũ (EMA) nắm bắt động lượng:
\begin{equation}
    x_{\text{EMA}}(t) = \alpha x(t) + (1-\alpha) x_{\text{EMA}}(t-1)
\end{equation}
với $\alpha = 2/(\text{span} + 1)$ cho span $\in \{30, 60, 120\}$ khung hình.

Thứ hạng phần trăm trong cửa sổ cung cấp ngữ cảnh:
\begin{equation}
    \text{rank\_pct}(v(t)) = \frac{\sum_{i \in w} \mathbb{1}[v(i) < v(t)]}{|w|}
\end{equation}
Đặc trưng này định vị vận tốc hiện tại trong phân phối cục bộ: giá trị cao (ví dụ 0.9) chỉ ra đỉnh hoạt động.

\subsection{Huấn Luyện Mô Hình}

\subsection{Cấu Hình XGBoost}

Bộ phân loại XGBoost sử dụng các siêu tham số: \texttt{n\_estimators}=250, \texttt{learning\_rate}=0.08, \texttt{max\_depth}=6, \texttt{min\_child\_weight}=5, \texttt{subsample}=0.8, \texttt{colsample\_bytree}=0.8.

\subsection{Chiến Lược Huấn Luyện Phân Cấp}

Huấn luyện tiến hành ở ba cấp: \textbf{(i)} Video được nhóm thành 9 phần dựa trên cấu hình bộ phận cơ thể được theo dõi; \textbf{(ii)} Với mỗi phần, các bộ phân loại riêng được huấn luyện cho hành vi đơn tác tử (mục tiêu = chính mình) và cặp đôi (mục tiêu $\neq$ chính mình); \textbf{(iii)} Mỗi hành động có bộ phân loại nhị phân độc lập với ngưỡng riêng.

\subsection{Kiểm Định Chéo và Tối Ưu Hóa}

Sử dụng StratifiedGroupKFold với $K=3$, đảm bảo tỷ lệ dương/âm cân bằng và tất cả khung hình từ cùng video ở cùng nhóm. Với mỗi hành động, ngưỡng quyết định tối ưu $\theta^*$ được tìm qua Optuna:
\begin{equation}
    \theta^* = \arg\max_{\theta} F_1(\hat{y} \geq \theta, y)
\end{equation}
với 1000 lần thử trên $\theta \in [0, 1]$.

\subsection{Hậu Xử Lý}

\subsubsection{Làm Mịn Gaussian}
Các dự đoán ngoài fold được làm mịn với trung bình cửa sổ cuộn:
\begin{equation}
    \hat{p}_{\text{smooth}}(t) = \frac{1}{w} \sum_{i=t-w/2}^{t+w/2} \hat{p}(i)
\end{equation}
với kích thước cửa sổ $w=15$ khung hình (0.5 giây ở 30 FPS).

\subsubsection{Dự Đoán Đa Lớp}
Tại mỗi khung hình, hành động có xác suất tối đa trên ngưỡng được chọn:
\begin{equation}
    a^*(t) = \begin{cases}
        \arg\max_{a} \hat{p}_a(t) & \text{nếu } \max_a \hat{p}_a(t) \geq \theta_a \\
        \emptyset & \text{ngược lại}
    \end{cases}
\end{equation}

\subsubsection{Làm Sạch Thời Gian}
Các dự đoán được hậu xử lý để loại bỏ:
\begin{itemize}
    \item Các khung hình mà bắt đầu $\geq$ kết thúc
    \item Các dự đoán trùng lặp từ cùng cặp tác tử-mục tiêu
    \item Các video không có dự đoán nào (điền với phân phối đều).
\end{itemize}

\section{Thực Nghiệm}

\subsection{Thiết Lập}

\textbf{Tập dữ liệu MABe} gồm 7,324 video huấn luyện từ 9 phòng thí nghiệm và 2,084 video kiểm tra, với 5-18 điểm mốc cơ thể mỗi chuột, tốc độ 20-60 FPS, và hơn 60 loại hành động.

\textbf{Chỉ số đánh giá.} Mouse F-beta score:
\begin{equation}
    F_\beta = \frac{(1+\beta^2) \cdot TP}{(1+\beta^2) \cdot TP + \beta^2 \cdot FN + FP}
\end{equation}
được tính theo từng hành động rồi lấy trung bình, với $\beta=1$ (F1-score). Sự chồng chéo khung hình xác định TP/FP/FN.

\textbf{Triển khai.} Kaggle Notebooks (CPU only), Python 3.11, XGBoost 2.0, thời gian chạy 10-12 giờ, bộ nhớ 12-14GB.

\subsection{Kết Quả}

Bảng~\ref{tab:results} hiển thị điểm F1 kiểm định theo phần. Phân tích tầm quan trọng đặc trưng cho thấy vận tốc đa tỷ lệ, độ cong và động lực khoảng cách quan trọng nhất. Cửa sổ 30-60 khung hình (1-2 giây) cung cấp thông tin nhiều nhất.

\begin{table}[!t]
\caption{Điểm F1 Kiểm Định theo Phần}
\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Phần} & \textbf{Đơn} & \textbf{Cặp} & \textbf{Hành động} \\
\midrule
1 (18 bộ phận) & 0.545 & 0.459 & 7 \\
2 (14 bộ phận) & 0.223 & 0.530 & 8 \\
3 (10 bộ phận) & 0.514 & 0.173 & 7 \\
4 (8 bộ phận) & --- & 0.418 & 6 \\
5 (7 bộ phận) & --- & 0.760 & 5 \\
6 (5 bộ phận) & 0.418 & 0.499 & 18 \\
7 (4 bộ phận) & 0.384 & 0.404 & 15 \\
8 (7 bộ phận) & 0.423 & 0.569 & 21 \\
9 (5 bộ phận) & 0.393 & 0.660 & 7 \\
\midrule
\textbf{Tổng} & \textbf{0.414} & \textbf{0.497} & \textbf{94} \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{center}
\end{table}

\textbf{Nghiên cứu loại bỏ.} Bảng~\ref{tab:ablation} cho thấy đóng góp tích lũy của các nhóm đặc trưng. Vận tốc đa tỷ lệ và độ cong đóng góp nhiều nhất, trong khi động lực xã hội quan trọng cho hành vi cặp đôi.

\begin{table}[!t]
\caption{Đóng Góp Nhóm Đặc Trưng}
\begin{center}
\begin{tabular}{lc}
\toprule
\textbf{Nhóm} & \textbf{$\Delta$ F1} \\
\midrule
Cơ bản & Baseline \\
+ Vận tốc đa tỷ lệ & +0.082 \\
+ Độ cong & +0.058 \\
+ Trạng thái chuyển động & +0.037 \\
+ Ngữ cảnh thời gian & +0.044 \\
+ Động lực xã hội & +0.052 \\
\midrule
\textbf{Đầy đủ} & \textbf{0.497} \\
\bottomrule
\end{tabular}
\label{tab:ablation}
\end{center}
\end{table}

\subsection{Thảo Luận}

\textbf{Điểm mạnh} bao gồm: (i) kỹ thuật tạo đặc trưng toàn diện nắm bắt mẫu đa tỷ lệ, (ii) huấn luyện phân cấp xử lý cấu hình không đồng nhất, (iii) tối ưu ngưỡng theo từng hành động, và (iv) triển khai hiệu quả trong ràng buộc tài nguyên.

\textbf{Hạn chế} gồm: (i) đặc trưng thủ công có thể bỏ sót mẫu phức tạp, (ii) phân loại độc lập khung hình bỏ qua phụ thuộc thời gian, (iii) 90\% nhãn thiếu hạn chế học từ toàn bộ dữ liệu, và (iv) hành vi hiếm thiếu mẫu dương.

\section{Kết Luận}
\subsection{Kết Luận }

Trong nghiên cứu này, chúng tôi đã xây dựng và đánh giá thành công một framework học máy toàn diện để nhận dạng tự động hành vi xã hội của chuột, giải quyết hiệu quả các thách thức của bộ dữ liệu MABe quy mô lớn. Giải pháp của chúng tôi dựa trên cốt lõi là thuật toán XGBoost kết hợp với kỹ thuật tạo đặc trưng (feature engineering) chuyên sâu, trích xuất hơn 150 đặc trưng bao gồm hình học, vận tốc đa tỷ lệ và ngữ cảnh thời gian.

Đóng góp quan trọng nhất của hệ thống là chiến lược huấn luyện phân cấp (hierarchical training), chia dữ liệu thành 9 phần dựa trên cấu hình bộ phận cơ thể. Cách tiếp cận này cho phép mô hình xử lý linh hoạt tình trạng thiếu hụt dữ liệu (missing keypoints) và sự không đồng nhất về điểm mốc giữa các video, đồng thời tối ưu hóa riêng biệt cho các hành vi đơn lẻ và hành vi cặp đôi. Bên cạnh đó, các đặc trưng về động lực xã hội và việc chuẩn hóa tọa độ sang đơn vị vật lý (cm) đã giúp mô hình vượt qua rào cản về sự thay đổi tỷ lệ pixel giữa các phòng thí nghiệm khác nhau. 

Kết quả thực nghiệm khẳng định rằng việc kết hợp các đặc trưng thủ công chất lượng cao với bộ phân loại cây quyết định (Gradient Boosting) có thể đạt hiệu suất tốt mà không cần tài nguyên tính toán quá lớn như các mô hình học sâu phức tạp. Hệ thống vận hành hiệu quả hoàn toàn trên CPU với thời gian huấn luyện từ 10-12 giờ và bộ nhớ 12-14GB, chứng minh tính khả thi cao trong việc triển khai thực tế. Cuối cùng, quy trình hậu xử lý bao gồm làm mịn Gaussian và tối ưu hóa ngưỡng qua Optuna đã đóng vai trò then chốt trong việc nâng cao độ chính xác (F1-score) và đảm bảo tính nhất quán về mặt thời gian của các hành vi dự đoán. 

\subsection{Công trình tương lai }
Mặc dù hệ thống hiện tại đã đạt được kết quả khả quan, vẫn còn nhiều dư địa để cải thiện hiệu suất, đặc biệt là trong việc xử lý các chuỗi thời gian phức tạp và dữ liệu mất cân bằng. Dựa trên các hạn chế đã nhận diện, chúng tôi đề xuất các hướng phát triển tiếp theo như sau: 

Mô hình hóa chuỗi thời gian với Deep Learning: Mô hình XGBoost hiện tại xử lý từng khung hình khá độc lập và phụ thuộc vào các đặc trưng cửa sổ trượt thủ công. Để nắm bắt tốt hơn các phụ thuộc dài hạn (long-term dependencies) mà các cửa sổ cố định có thể bỏ lỡ, chúng tôi dự kiến tích hợp các kiến trúc mạng nơ-ron hồi quy như LSTM (Long Short-Term Memory) hoặc GRU (Gated Recurrent Units). Đặc biệt, cơ chế Attention (Chú ý) sẽ được áp dụng để giúp mô hình tự động tập trung vào các đoạn tương tác xã hội quan trọng thay vì xử lý dàn trải toàn bộ chuỗi thời gian. 

Phương pháp Tập hợp (Ensemble Learning) nâng cao: Để giảm thiểu phương sai và tăng độ ổn định của dự đoán, chúng tôi sẽ mở rộng chiến lược mô hình đơn lẻ sang phương pháp tập hợp (Ensembling). Cụ thể, việc kết hợp kết quả dự đoán từ XGBoost với các mô hình Gradient Boosting khác như LightGBM (tối ưu tốc độ) và CatBoost (xử lý tốt đặc trưng phân loại) hứa hẹn sẽ cải thiện đáng kể điểm số F1 tổng thể. 

Khai thác dữ liệu chưa gán nhãn (Semi-supervised Learning): Hiện tại, 90\% dữ liệu trong tập huấn luyện bị thiếu nhãn hành vi, gây lãng phí thông tin lớn. Trong tương lai, chúng tôi sẽ áp dụng các kỹ thuật học bán giám sát (Semi-supervised learning) để tận dụng lượng dữ liệu khổng lồ này, cho phép mô hình học được các biểu diễn đặc trưng mạnh mẽ hơn về chuyển động của chuột mà không cần phụ thuộc hoàn toàn vào nhãn thủ công. 

Tăng cường dữ liệu cho hành vi hiếm: Một số hành vi xã hội quan trọng xuất hiện rất ít trong tập dữ liệu, dẫn đến hiện tượng mất cân bằng lớp nghiêm trọng. Chúng tôi đề xuất sử dụng các kỹ thuật tăng cường dữ liệu (Data Augmentation) chuyên biệt cho chuỗi thời gian như kéo dãn thời gian (time stretching) hoặc phương pháp SMOTE để sinh thêm các mẫu giả lập cho các hành vi hiếm, giúp mô hình học cân bằng hơn. 

Nâng cao tính nhất quán thời gian và Đặc trưng: Thay vì chỉ làm mịn Gaussian đơn giản, chúng tôi sẽ nghiên cứu áp dụng Conditional Random Fields (CRF) ở bước hậu xử lý để mô hình hóa xác suất chuyển đổi giữa các trạng thái hành vi, đảm bảo chuỗi hành vi dự đoán tuân theo logic thực tế. Ngoài ra, việc bổ sung các đặc trưng nâng cao như biến đổi Wavelet (phân tích tần số-thời gian) và đặc trưng đồ thị (Graph features) sẽ giúp mô tả tốt hơn cấu trúc tương tác giữa các tác tử. 
% --- PHỤ LỤC: THUẬT NGỮ ---
\section*{Phụ Lục A \\ Giải Thích Thuật Ngữ Chuyên Ngành} 
\begin{itemize}
    \item \textbf{XGBoost (eXtreme Gradient Boosting):} Một thuật toán học máy dựa trên cây quyết định (decision tree) sử dụng kỹ thuật tăng cường độ dốc (gradient boosting), được tối ưu hóa về tốc độ và hiệu năng.
    \item \textbf{Optuna:} Một framework phần mềm tự động hóa việc tối ưu hóa siêu tham số (hyperparameter tuning), sử dụng thuật toán lấy mẫu hiệu quả để tìm ra cấu hình tốt nhất cho mô hình học máy.
    \item \textbf{StratifiedGroupKFold:} Một chiến lược kiểm định chéo (cross-validation) đảm bảo rằng các mẫu từ cùng một nhóm (trong trường hợp này là cùng một video) không bị tách ra giữa tập huấn luyện và tập kiểm thử, đồng thời giữ nguyên tỷ lệ phân bố nhãn.
    \item \textbf{Mouse F-beta Score:} Một biến thể của độ đo F-score, dùng để đánh giá độ chính xác của mô hình phân loại. Với $\beta=1$ (được sử dụng trong bài này), nó trở thành F1-score, là trung bình điều hòa của độ chính xác (Precision) và độ phủ (Recall).
    \item \textbf{Gaussian Smoothing (Làm mịn Gaussian):} Một kỹ thuật hậu xử lý sử dụng bộ lọc Gaussian (phân phối chuẩn) để làm mượt chuỗi xác suất dự đoán theo thời gian, giúp loại bỏ các nhiễu ngắn hạn và làm cho các đoạn hành vi liền mạch hơn.
    \item \textbf{Feature Engineering (Kỹ thuật tạo đặc trưng):} Quá trình sử dụng kiến thức miền (domain knowledge) để trích xuất các thông tin quan trọng (như vận tốc, góc quay) từ dữ liệu thô, giúp thuật toán học máy hoạt động hiệu quả hơn.
\end{itemize}
% --------------------------

\begin{thebibliography}{00}
\bibitem{anderson2014toward} D. J. Anderson and P. Perona, ``Toward a science of computational ethology,'' \textit{Neuron}, vol. 84, no. 1, pp. 18--31, 2014.
\bibitem{mathis2018deeplabcut} A. Mathis et al., ``DeepLabCut: markerless pose estimation of user-defined body parts with deep learning,'' \textit{Nature Neuroscience}, vol. 21, no. 9, pp. 1281--1289, 2018.
\bibitem{pereira2019sleap} T. D. Pereira et al., ``SLEAP: A deep learning system for multi-animal pose tracking,'' \textit{Nature Methods}, vol. 19, no. 4, pp. 486--495, 2022.
\bibitem{kabra2013jaaba} M. Kabra et al., ``JAABA: interactive machine learning for automatic annotation of animal behavior,'' \textit{Nature Methods}, vol. 10, no. 1, pp. 64--67, 2013.
\bibitem{luxem2022identifying} K. Luxem et al., ``Identifying behavioral structure from deep variational embeddings of animal motion,'' \textit{Nature Communications}, vol. 13, no. 1, p. 6235, 2022.
\bibitem{chen2016xgboost} T. Chen and C. Guestrin, ``XGBoost: A scalable tree boosting system,'' in \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 2016, pp. 785--794.
\bibitem{segalin2021mouse} C. Segalin et al., ``The Mouse Action Recognition System (MARS) software pipeline for automated analysis of social behaviors in mice,'' \textit{eLife}, vol. 10, p. e63720, 2021.
\end{thebibliography}

\end{document}